# ğŸ§ Penguins of Madagascar - Species Classification

This repository classifies penguin species based on bill length, bill depth and flipper length, and . It includes an automated pipeline that fetches new penguin data daily from an API and predicts its species.

## ğŸš€ Features
- **Feature Selection**: Identifies the most relevant features using Mutual Information, RFE, Random Forest, and Permutation Importance.
- **Model Training**: Uses **Random Forest Classifier** for species classification.
- **Automated Data Retrieval**: Fetches new penguin data from an API every morning at 07:30 AM.
- **GitHub Actions Integration**: Automates prediction updates.
- **GitHub Pages Deployment**: Displays the latest prediction --> [Penguin Prediction](https://pd-bds.github.io/MLOps/)

---

## ğŸ“‚ **Repository Structure**
```bash
Penguins-of-Madagascar/
â”‚â”€â”€ .github/workflows               # Github Actions workflow
    â”‚â”€â”€ daily_prediction.yml
â”‚â”€â”€ Model Training
    â”‚â”€â”€model_training.ipynb         # Feature selection and model training
    â”‚â”€â”€penguins.db                  # SQL Database
    â”‚â”€â”€penguinsDB.py                # Database Creation file      
â”‚â”€â”€ prediction.py                   # Prediction using API data and output in html
â”‚â”€â”€ penguins_classifier.pkl         # Trained model
â”‚â”€â”€ requirements.txt                # dependencies
â”‚â”€â”€ README.md                       # Documentation (this file)
â”‚â”€â”€ scaler.pkl                      # Saved scaler
```

---

## ğŸ“Š **Feature Selection**

To identify the most relevant features, the following methods were used:

```

echo "Feature              | Mutual Info | RFE | Random Forest | Permutation | Importance"
echo "---------------------|-------------|-----|---------------|-------------|-------------"
echo "bill_length_mm       | âœ…           | âœ…   | âœ…             | âœ…           | Important âœ…"
echo "bill_depth_mm        | âœ…           | âœ…   | âœ…             | âŒ           | Important âœ…"
echo "flipper_length_mm    | âœ…           | âœ…   | âœ…             | âœ…           | Important âœ…"
echo "body_mass_g          | âŒ           | âŒ   | âŒ             | âŒ           | Not Important âŒ"
echo "sex_Female           | âŒ           | âŒ   | âŒ             | âŒ           | Not Important âŒ"
echo "sex_Male             | âŒ           | âŒ   | âŒ             | âŒ           | Not Important âŒ"
echo "island_Biscoe        | âŒ           | âŒ   | âŒ             | âŒ           | Not Important âŒ"
echo "island_Dream         | âŒ           | âœ…   | âŒ             | âœ…           | Not Important âŒ"
echo "island_Torgersen     | âŒ           | âŒ   | âŒ             | âŒ           | Not Important âŒ"
```

ğŸš€ Final features used in the model:
- `bill_length_mm`, `bill_depth_mm`, `flipper_length_mm`

---

## ğŸ† **Model Training**

The model was trained using **Random Forest Classifer**, achieving an accuracy of 99%.

**Model Performance**:
- Test Accuracy: 99%
- Cross-Validation Accuracy: 99% Â± 0.00

**The trained model is saved as**:
```
models/penguin_classifier.pkl
```

---

## ğŸ”„ **Automated Prediction Pipeline**

ğŸ”¹ **1ï¸âƒ£ Fetch New Penguin Data**

New penguins data are fetched by making API calls to http://130.225.39.127:8000/new_penguin/

ğŸ”¹ **2ï¸âƒ£ Make Prediction**

prediction are made using the trained model and the prediction is shown as a html output for showing it as a github page.

ğŸ”¹ **3ï¸âƒ£ Automating with GitHub Actions**

GitHub Actions runs every day at 07:30 AM and updates the github page (https://pd-bds.github.io/MLOps/)


## **ğŸ›  Running the Project Locally**

To test the project locally, follow these steps:

1ï¸âƒ£ Clone the repository:

```bash
git clone https://github.com/PD-BDS/MLOps.git
cd MLOps
```

2ï¸âƒ£ Install dependencies:

```bash
pip install -r requirements.txt
```


4ï¸âƒ£ Run the prediction script:

```bash
python prediction.py
```

5ï¸âƒ£ Check the latest prediction:
open the index.html file to see the html output

---
